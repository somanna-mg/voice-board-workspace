# **üé§ Whisper STT Service - Product Requirements Document (PRD)**

## **üìã Executive Summary**

We're building a local speech-to-text (STT) service that converts voice recordings into text for the Voice Board teaching tool. Think of it as your personal transcription assistant that runs entirely on your computer - no internet needed!

**Why are we building this?**
- Teachers need to create teaching materials quickly using voice commands
- Cloud STT services are expensive and require internet
- Privacy matters - audio should never leave your computer
- We want sub-second response times for a smooth experience

---

## **üéØ What We're Building**

### **The Big Picture**

Imagine you're a teacher creating a lesson about arrays. Instead of clicking and typing, you simply say:
> *"Create an array with 5 elements"*

Our STT service is the first step - it converts your voice into text that our system can understand.

### **Core Functionality**

1. **Listen** ‚Üí Accept audio from your microphone or browser
2. **Convert** ‚Üí Transform speech into accurate text using OpenAI's Whisper AI model
3. **Respond** ‚Üí Return the text in under 700 milliseconds
4. **Scale** ‚Üí Handle multiple requests without slowing down

---

## **ü§î Key Decisions & Why We Made Them**

### **Decision 1: Local-First Architecture**

**What we chose**: Run everything on your computer
**Why**: 
- üîí **Privacy**: Your voice never leaves your machine
- üí∞ **Cost**: No per-request API fees
- ‚ö° **Speed**: No network latency
- üåê **Offline**: Works without internet

**Trade-off**: Users need to install software (worth it for privacy/speed)

### **Decision 2: Whisper with small.en Model**

**What we chose**: OpenAI's Whisper `small.en` model (244MB)
**Why**:
- ‚úÖ 95%+ accuracy for everyday English
- ‚úÖ Fast enough for real-time use
- ‚úÖ Proven technology (millions of users)
- ‚úÖ Free and open-source

**Why not tiny/base?**: Too many errors on teaching terminology
**Why not medium/large?**: Too slow for interactive use

### **Decision 3: Microservice Architecture**

**What we chose**: Separate STT service on port 5174
**Why**:
- üîß Can update STT without touching main app
- üöÄ Can scale independently
- üß™ Easier to test in isolation
- üîÑ Can swap implementations later

**Alternative rejected**: Embedding in web app (too heavy, platform-specific)

### **Decision 4: Hardware Acceleration**

**What we chose**: Auto-detect and use GPU when available
**Why**:
- üèéÔ∏è 2-3x faster with GPU
- üîÑ Falls back to CPU automatically
- üë• Works for everyone (GPU users get speed boost)

---

## **üìê Technical Architecture**

### **System Overview**

```
Your Computer:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Chrome/Firefox/Safari             ‚îÇ
‚îÇ   üì± Voice Board Web App            ‚îÇ
‚îÇ   (localhost:3000)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ HTTP/WebSocket
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   üé§ STT Service                    ‚îÇ
‚îÇ   (localhost:5174)                  ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Express.js Server            ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Whisper.cpp Engine           ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Audio Processor (FFmpeg)     ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ Worker Pool Manager          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Request Flow**

1. **User speaks** into microphone
2. **Browser records** audio (WebM format usually)
3. **Uploads to STT** service via HTTP POST
4. **FFmpeg converts** to standard format (16kHz WAV)
5. **Whisper processes** using optimal hardware (GPU/CPU)
6. **Text returned** to browser
7. **Command Router** interprets the text (separate service)

---

## **üõ†Ô∏è Feature Specifications**

### **Feature 1: Audio Processing Pipeline**

**Goal**: Accept any common audio format and standardize it

**How it works**:
```
Input Audio ‚Üí FFmpeg ‚Üí 16kHz Mono WAV ‚Üí Whisper
(any format)           (standard format)
```

**Supported formats**:
- ‚úÖ WebM/Opus (browser default)
- ‚úÖ WAV (uncompressed)
- ‚úÖ MP3 (compressed)
- ‚úÖ M4A/AAC (Apple devices)
- ‚úÖ OGG (open source)

**Why FFmpeg?**: Industry standard, handles everything

### **Feature 2: Smart Hardware Detection**

**Goal**: Use the fastest available hardware automatically

**Detection order**:
1. Check for NVIDIA GPU ‚Üí Use CUDA acceleration
2. Check for Apple Silicon ‚Üí Use Metal acceleration  
3. Check for AMD GPU ‚Üí Use ROCm if available
4. Fallback ‚Üí Use CPU with SIMD optimizations

**User experience**: It just works - no configuration needed!

### **Feature 3: Concurrent Processing**

**Goal**: Handle multiple users/requests simultaneously

**Implementation**:
- **Worker pool** with N processes (N = CPU cores / 2)
- **Queue system** prevents overload
- **Request timeout** after 2 minutes
- **Graceful degradation** when busy

**Example**: 4-core CPU = 2 whisper workers running in parallel

### **Feature 4: Result Caching**

**Goal**: Don't process the same audio twice

**How it works**:
- Hash audio content ‚Üí Use as cache key
- Store text result for 2 minutes
- Instant response for duplicate requests

**Why cache?**: Teachers often repeat commands

---

## **üìä Performance Requirements**

### **Latency Targets**

| Audio Length | Target | Why This Matters |
|--------------|--------|------------------|
| 5 seconds | ‚â§ 700ms | Feels instant to users |
| 10 seconds | ‚â§ 1.4s | Still interactive |
| 30 seconds | ‚â§ 4.2s | Max supported length |

### **Accuracy Targets**

| Content Type | Target | Example |
|--------------|--------|---------|
| Simple commands | 98%+ | "create an array" |
| Technical terms | 95%+ | "binary search tree" |
| Full sentences | 93%+ | Complex explanations |

### **Resource Usage**

- **RAM**: ~500MB base + 300MB per worker
- **CPU**: 50-100% during processing (brief spikes)
- **Disk**: 250MB for model + temp files
- **Network**: None (fully local!)

---

## **üö¶ API Specification**

### **Health Check Endpoint**

```
GET /health

Response:
{
  "status": "healthy",
  "version": "1.0.0",
  "model": "small.en",
  "hardware": "NVIDIA GPU (CUDA)",
  "workers": 2,
  "queue": 0
}
```

### **Transcription Endpoint**

```
POST /api/whisper
Content-Type: multipart/form-data

Fields:
- audio: File (required) - Audio file to transcribe
- language: String (optional) - Always "en" for now

Response:
{
  "text": "Create an array with five elements",
  "confidence": 0.95,
  "duration": 487,  // milliseconds
  "cached": false
}
```

### **Error Responses**

```json
// Audio too long
{
  "error": "Audio duration exceeds maximum (45s > 30s)",
  "code": "AUDIO_TOO_LONG"
}

// Service busy
{
  "error": "Service temporarily unavailable - queue full",
  "code": "QUEUE_FULL"
}
```

---

## **üéÆ User Experience**

### **Installation Flow**

1. **Download installer** for your platform (Mac/Windows)
2. **Run installer** 
   - Installs service files
   - Downloads Whisper model (one-time, 244MB)
   - Sets up auto-start
3. **Service starts** automatically
4. **Open web app** - voice features work immediately!

### **Daily Usage**

- Service runs in background (like Dropbox)
- System tray/menu bar icon shows status
- No configuration needed
- Automatic updates (future feature)

### **First-Time Setup Time**

- Download installer: 1 minute (10MB)
- Install service: 30 seconds
- Download model: 2-5 minutes (244MB)
- **Total**: Under 7 minutes to voice-enabled!

---

## **üîí Security & Privacy**

### **Data Handling**

- ‚úÖ Audio files deleted immediately after processing
- ‚úÖ No logs contain audio content
- ‚úÖ Result cache only stores text (not audio)
- ‚úÖ All processing happens locally

### **Network Security**

- Service only listens on localhost (not exposed to network)
- No external API calls
- No telemetry or usage tracking

---

## **üèóÔ∏è Implementation Priorities**

### **Phase 1: Core Functionality (Week 1)**
- Basic Express server
- Whisper integration (CPU only)
- File upload support
- Simple health check

### **Phase 2: Production Ready (Week 2)**
- GPU acceleration
- Worker pool for concurrency  
- Result caching
- Error handling

### **Phase 3: Polish (Week 3)**
- Platform installers
- System tray integration
- Performance monitoring
- Comprehensive testing

---

## **‚ùì FAQs for Developers**

**Q: Why not use browser's Web Speech API?**
- A: Requires internet, sends data to Google/Apple, less accurate for technical terms

**Q: Why TypeScript instead of Python?**
- A: Matches our monorepo stack, better for long-running services, easier deployment

**Q: Can we add more languages later?**
- A: Yes! Just switch from `small.en` to `small` model (supports 99 languages)

**Q: What if Whisper gets outdated?**
- A: Service architecture allows swapping to any STT engine without changing API

**Q: How do we handle accents?**
- A: Whisper small.en handles most English accents well; can fine-tune later if needed

---

## **‚úÖ Success Metrics**

### **Technical Success**
- ‚úÖ 95%+ requests under 700ms (5-second audio)
- ‚úÖ 99%+ accuracy on basic commands
- ‚úÖ Zero network requests during operation
- ‚úÖ Handles 10+ concurrent requests

### **User Success**
- ‚úÖ Setup in under 10 minutes
- ‚úÖ Works immediately (no configuration)
- ‚úÖ Transparent operation (users forget it's there)
- ‚úÖ No monthly fees

---

## **üöÄ Future Enhancements (Post-MVP)**

1. **Streaming transcription** - Real-time text as you speak
2. **Speaker diarization** - Identify who's speaking
3. **Custom vocabulary** - Add technical terms specific to curriculum
4. **Cloud hybrid mode** - Optional cloud fallback for older machines
5. **Multi-language support** - Switch to multilingual model

---

## **üìù Summary**

We're building a local STT service that's:
- **Fast** (under 700ms response)
- **Private** (fully local)
- **Accurate** (95%+ on technical content)
- **Simple** (works out of the box)

This forms the foundation of our voice-driven teaching tool, converting speech to text that our command system can understand.

---

**PRD OK to task-plan? (yes / revise)**

Need clarification on any section? Want me to expand on any technical decision?